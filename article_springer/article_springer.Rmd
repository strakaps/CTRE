---
title: Inference for Continuous Time Random Maxima with Heavy-Tailed Waiting Times 
titlerunning: Inference for Heavy-Tailed CTRMs
thanks: |
    Peter Straka was supported by the 
    Discovery Early Career Research Award DE160101147 on the Project 
    "Predicting Extremes when Events Occur in Bursts" by the Australian
    Research Council.
    Katharina Hees was supported by 
    the DAAD co-financed by the German Federal Ministry of Education and 
    Research (BMBF). 
   
authors: 
- name: "Katharina Hees"
  address: University of Dortmund
  email: hees@statistik.uni-dortmund.de
  
- name: "Smarak Nayak"
  address: National Australia Bank
  email: smarak.nayak@nab.com.au
  
- name: "Peter Straka*"
  address: UNSW Sydney
  email: p.straka@unsw.edu.au 
  
authorrunning: Hees, Nayak & Straka

keywords:
- heavy tails
- renewal process
- extreme value theory
- peaks over threshold

abstract: |
  In many complex
  systems of interest, inter-arrival times between events such as 
  earthquakes, trades and neuron voltages have a heavy-tailed 
  distribution. 
  The set of event times is fractal-like, being dense in some 
  time windows and empty in others, a phenomenon dubbed 
  "bursty" in the physics literature. 
  Renewal processes with heavy-tailed waiting times reproduce this bursty 
  behaviour. 
  
  This article develops an inference method for 
  "Continuous Time Random Maxima" (also called "Max-renewal processes"), 
  which
  assume i.i.d. magnitudes at the renewal events and model the largest
  cumulative magnitude.
  For high thresholds and infinite-mean waiting times, we show that the 
  times between threshold crossings 
  are Mittag-Leffler distributed, i.e. form a fractional Poisson Process. 
  Exceedances of thresholds are known to be Generalized Pareto distributed,
  according to the Peaks Over Threshold approach. 
  We model threshold crossing times and threshold exceedances jointly and
  provide graphical means of estimating model parameters.
  We show that these methods yield meaningful insights on real-world 
  datasets.

bibliography: CTRMstats.bib

output: rticles::springer_article

params:
  tail: 0.8
  n: 10000

---

```{r get-rticles, eval=FALSE, include=FALSE}
# use this rticles version: 
devtools::install_github("strakaps/rticles", 
                         ref = "724aeb88d005e2f7befc37328633e7cb2bc1cce0")
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  cache = TRUE,
  message = FALSE,
  fig.height = 3.5
  )
library(CTRM)
```


# Introduction

Time series displaying temporally inhomogeneous behaviour have received 
strong interest in the recent statistical physics literature 
[@Barabasi2005; @Oliveira2005; @Vasquez2006; @Vazquez2007; @Omi2011; 
@Min2010; @Karsai2011; @Bagrow2013], and have been observed in the context 
of earthquakes, sunspots, neuronal activity and human communication [see 
@Karsai2012; @Vajna2013 and @MeerschaertStoev08 for a list of references]. 
Such time series exhibit high activity in some 'bursty' intervals, which 
alternate with other, quiet intervals.  Although several mechanisms are 
plausible explanations for bursty behaviour (most prominently self-exciting
point processes [@hawkes1971point]), there seems to be one salient feature 
which very typically indicates the departure from temporal homogeneity: a 
heavy-tailed distribution of waiting times [@Vasquez2006; @Karsai2012; 
@Vajna2013]. As we show below in simulations, a simple renewal process with
heavy-tailed waiting times can capture this type of dynamics. For many 
systems, the renewal property is appropriate; a simple test of the absence 
of correlations in a succession of waiting times can be undertaken by 
randomly reshuffling the waiting times [@Karsai2012].

Often a magnitude, or mark can be assigned to each event in the renewal process, 
such as for earthquakes, sun flares or neuron voltages. 
Extreme value theory provides models for the distribution of the events
with the largest magnitude. 
A commonly made assumption is that times between events are either fixed 
or light-tailed, and this entails that the times at which a (high) 
threshold is crossed form a Poisson process [@beirlantBook]. 
In the heavy-tailed waiting time scenario, as we will see, threshold 
crossing times form a *fractional Poisson process*, which generalizes 
the standard Poisson process. 
Maxima of events which occur according to a renewal process with
heavy-tailed waiting times have been studied under 
the names "Continuous Time Random Maxima process" (CTRM) 
[@Benson2007; @MeerschaertStoev08; @Hees16; @Hees17], 
"Max-Renewal process" [@Silvestrov2002a; @ST04; @Basrak2014], 
and "Shock process"
[@Esary1973; @Sumita1983; @Sumita1984; @Sumita1985; @Anderson1987; @Gut1999].
The existing literature focuses on probabilistic results surrounding these 
models. 
In this work, however, we introduce a method of inference for this type of 
model, a problem which has seemingly received little attention so far, 
even by the statistical community.

We review the CTRM, or max-renewal model, in Section 2, and 
derive a scaling limit theorem for inter-exceedance times in Sections 3 &
4. 
A statistical procedure to estimate model parameters via stability plots 
is outlined in Section 5, and diagnostic plots for model criticism are 
discussed in Section 6. 
In Section 7, we give case studies for simulated data as well as for two
real-world datasets, with a discussion in Section 8. 
All statistical computations have been done in R, and all code, data, as 
well as the source code for this manuscript has been organized into an R 
software package, available at 
\url{https://github.com/strakaps/CTRM}. 


# CTRMs

![\label{fig:ctrm} A CTRM sample path.](just-tikz-figure0.pdf)

Continuous Time Random Maxima (CTRM), or Max-Renewal processes, track the 
largest event in a renewal sequence of events [@Basrak2014; 
@MeerschaertStoev08; @Hees16]:

Definition (CTRM): 

: Let $(W,J), (W_1, J_1), (W_2, J_2), \ldots$ be i.i.d. pairs of random 
variables, where the $W_k > 0$ are interpreted as the *waiting times* or 
inter-arrival times and $J_k \in [x_L, x_R]$ as the *event magnitudes* 
or marks
($x_L \in [-\infty, +\infty), x_R \in (-\infty, +\infty]$). 
The renewal process associated with the $W_k$ is 
$$N(t) = \max\{n: W_1 + \ldots + W_n \le t\},$$
and the running maximum is $M(n) := \bigvee_{k=1}^n J_k$. Then the process
$$V(t)=M(N(t)) = \bigvee_{k=1}^{N(t)} J_k, \quad t \ge 0.$$
is called a CTRM (Continuous Time Random Maxima) process. 
If $W$ and $J$ are independent, the CTRM is said to be *uncoupled*. 
We let $M(0) = x_L$.

Figure \ref{fig:ctrm} shows a CTRM sample path.
The alternative case where one considers the maximum of the first 
$(N(t)+1)$'s event is called an *OCTRM process* (Overshooting Continuous 
Time Random Maxima; or *Model II* by @Sumita1983). 
The conceptual difference between CTRM and OCTRM is the order of waiting 
times and events, which is $W_1,J_1,W_2,J_2,..$ for the CTRM and 
$J_1,W_1,J_2,W_2,...$ for the OCTRM. 
In the uncoupled case, unsurprisingly CTRM and OCTRM are asymptotically 
equivalent. 
In the coupled case, however, their distributions 
can be dramatically different [@Hees16].

The main purpose of this article is to introduce and discuss a method for 
fitting data to an uncoupled CTRM. The following two quantities are our main 
ingredients.

Definition: 

: The random variables
$$X(\ell) = V(T(\ell)) - \ell, \quad 
T(\ell) = \inf\{t: V(t) > \ell\}, 
\quad \ell \in (x_L, x_R)$$
are called the *exceedance* resp. *time until exceedance* of level $\ell$.

#### POT-like approach.
Since we assume the uncoupled case, $X(\ell)$ and $T(\ell)$ are 
independent. 
To see this, note that $X(\ell)$ is, in distribution, simply equal to
$J | J > \ell$, independent of any waiting times $W_k$. 
For our inference on the CTRM model, we will extract realizations of 
$X(\ell)$ and $T(\ell)$ from data by considering thresholds 
$\ell$ ranging over some interval $[\ell_0, x_R)$. 
(For instance, let $\ell_0$ equal the $95$-th percentile of $J$.)
Write $X(\ell,i)$ for the $i$-th exceedance of level $\ell$, 
and $T(\ell,i)$ for the inter-arrival time between
$X(\ell,i-1)$ and $X(\ell,i)$. 
Thus for any threshold $\ell \in [\ell_0, x_R)$,
we construct sequences $\{T(\ell,i)\}_{i}$ and 
$\{X(\ell,i)\}_{i}$. 
These sequences are i.i.d. since the underlying $W_k$ and $J_k$
are i.i.d., and independent because $W_k$ and $J_k$ are uncoupled.
Extracting the exceedances $X(\ell)$ for inference is a standard procedure
known as the Peaks Over Threshold (POT) approach in extreme value theory
[@beirlantBook].
Figure \ref{fig:thresholdedBursty} illustrates the exceedances 
$X(\ell, i)$ in red and the times until exceedance $T(\ell, i)$ as the 
preceding intervals marked by blue crosses. 

```{r thresholdedBursty, message=FALSE, fig.cap="\\label{fig:thresholdedBursty}Exceedances (red) and Times until Exceedance (durations between blue crosses) for a given threshold $\\ell$ (dashed line)."}
#rpareto <- function(n,tail){
#          if(tail<=0) stop("tail must be positive")
#          rp <- (runif(n)/gamma(1-tail))^(-1/tail)
#          rp}
tail <- params$tail
n <- params$n 
sigma <- (cos(pi*tail/2))^(1/tail)
times <- cumsum(stabledist::rstable(n, tail, 1, sigma, pm=1))
#times<-cumsum(rpareto(n,tail))
magnitudes <- extRemes::revd(n, scale = 1, shape = 0)
sim_ctrm <- ctrm(data.frame(times, magnitudes))
plot(sim_ctrm, p = 0.005)
```

A standard result from extreme value theory provides the asymptotic 
distribution of $X(\ell)$ as $\ell \uparrow x_R$. For later use, we also 
include the scaling limit of the cumulative maximum $M(n)$. 

Theorem GEV (e.g. Chapter 2 & Section 5.3, @beirlantBook):

: Suppose the distribution of $J_k$ is continuous. Then there
exist non-decreasing norming functions $a(c)$ and $d(c)$ such that
as $c \to \infty$, the running maximum\footnote{We extend $M(n)$ 
continuously to $[0, +\infty)$ via $M(c) := M(\lfloor c \rfloor)$ where 
$\lfloor c \rfloor$ is the 
greatest integer not greater than $c$.} 
$M(c)$ converges weakly 
to a *Generalized Extreme Value Distribution* with shape
parameter
$\xi$:
\begin{align}
[M(c) - d(c)] / a(c) \stackrel{d}{\to} A, 
\quad
\mathbf P(A \le z) = G(z | \xi) = \exp\left(-[1+\xi z]^{-1/\xi}\right),\label{eq:GEV}
\end{align}
defined for all $z$ such that $1 + \xi z > 0$. 
This definition extends continuously to $\xi = 0$ via 
$$G(z | 0) = \exp(-\exp(-x)).$$
For $\mu$ and $\sigma > 0$, we write ${\rm GEV}(\xi, \mu, \sigma)$ for the 
probability distribution of the random variable $\sigma A + \mu$. 

    Moreover, asymptotically as $\ell \uparrow x_R$,
$$\mathbf P(J - \ell > y | J > \ell) 
\sim 1 - H(y),$$
where 
$$H(y) = \begin{cases}
1 - (1+ \xi y / \tilde \sigma)^{-1/\xi}, & y \in (0,\infty) \text{ if } \xi > 0,\\
1 - \exp(-y/\tilde \sigma), & y \in (0,\infty) \text{ if } \xi = 0,\\
1 - (1+ \xi y / \tilde \sigma)^{-1/\xi}, & y \in (0, -\sigma / \xi) \text{ if } \xi < 0
\end{cases}$$

    and where $\tilde \sigma := \sigma + \xi(\ell-\mu)$.
The CDF $H(y)$ is said to belong to the *Generalised Pareto family*
$GP(\xi,\bar \sigma)$.


# CTRM Scaling limits

## Waiting times

We will assume that the waiting times $W_k$ have infinite mean,
i.e. a tail parameter $\beta \in (0,1)$ and regularly varying tail probabilities:
$\mathbf P(W > t) \sim L(t) t^{-\beta}$ as $t \uparrow \infty$ for
some slowly varying function $L(t)$. As usually, $f(t) \sim g(t)$
means that the quotient of $f(t)$ and $g(t)$ converges to $1$. The
law of the $W$ then lies in the domain of attraction of a stable law,
in the sense that the distributional limit 
\begin{align} \label{eq:Wscale}
\frac{W_1 + \ldots + W_n}{b(n)} \overset{d}{\longrightarrow} D, 
\quad n \to \infty
\end{align}
exists, for a regularly varying scaling function
\begin{equation} \label{eq:bScale}
b \in {\rm RV}_\infty(1/\beta)
\end{equation}
[See e.g. Section 2.9.2 in @beirlantBook for a short introduction to 
regular variation]. 
The limit is then a positively skewed stable distribution, 
whose scale parameter is $1$ if $b(n)$ is chosen accordingly
[see e.g. Section 3.7 in @MeerschaertSikorskii]. 
This distribution is most concisely defined via its Laplace transform
\begin{align} \label{theD}
\mathbf E[\exp(-sD)] = \exp(-s^\beta).
\end{align}
Moreover, the following functional limit theorem holds 
[see e.g. Remark 4.17 in @MeerschaertSikorskii]: 
\[
(W_1 + \ldots + W_{\lfloor ct \rfloor})/b(c) \overset{d}{\longrightarrow} D(t), \quad c \to \infty
\] 
with convergence in the Skorokhod $J_1$ topology. The limit
$D(t)$ is a stable subordinator, i.e. an increasing LÃ©vy process with
Laplace transform $\exp(-t s^\beta)$.


It is well known [see e.g. @limitCTRW] that the renewal
process then satisfies the functional limit
$$
N(ct)/ \tilde b(c) \stackrel{d}{\to} E(t) = \inf\{r: D(r) > t\}, 
\quad c \to \infty
$$
for a scaling function $\tilde b(c) \in {\rm RV}_\infty(\beta)$ which is asymptotically inverse to $b(c)$, in the sense of @seneta (p.20): 
$$
b(\tilde b(c)) \sim c \sim \tilde b(b(c)).
$$
[also see Prop 4.15 in @MeerschaertSikorskii]. 
The limit process $E(t)$ is called the _inverse stable subordinator_ [@invSubord].

## Magnitudes and Extreme Value Distributions

The extremal limit theorem then allows for an extension to functional 
(i.e. pathwise) limits: assume that the norming sequences $a(c)$ and 
$d(c)$ are as in Theorem GEV. Then 
$$
[M(ct) - d(c)] / a(c) \stackrel{d}{\to} A(t),
\quad c \to \infty.
$$
Here convergence holds weakly in Skorokhod's $J_1$ topology, and the limit
process $A(t)$ is an _extremal process_, with
finite-dimensional distributions given by
\begin{align}
\label{eq:fin-dim-A}
\mathbf P(A(t_i)\leq x_i,1\leq i \leq d) 
= F_A(\wedge_{i=1}^d x_i)^{t_1} 
F_A(\wedge_{i=2}^d x_i)^{t_2-t_1}
\ldots F_A(x_d)^{t_d-t_{d-1}},
\end{align}
where $F_A(x)$ is a GEV distribution [see e.g. @resnick2013extreme]. 

## CTRM limit

The CTRM $V(t)$ results from the running maximum $M(n)$ via a time change by the renewal process $n = N(t)$. This is also reflected in its corresponding limit process:

Theorem MS1 [@MeerschaertStoev08]: 

: The CTRM process $V(t) = M(N(t))$ satisfies the following functional scaling limit in the Skorokhod $J_1$ topology: 
$$
[V(ct) - d(\tilde b(c))] / a(\tilde b(c)) \stackrel{d}{\to} 
A(E(t)), \quad c \to \infty.
$$

The distribution of the _hitting time_ of a level $\ell^*$ by the limit 
process $A(E(t))$ is also known:

Theorem MS2 [@MeerschaertStoev08]: 

: Let $F_A$ be the CDF of a GEV distribution, and let $A(t)$ be the
extremal process corresponding to $F_A$ via \eqref{eq:fin-dim-A}. 
For a given threshold $\ell^*$ in the support of $F_A$,
the hitting time
$$
B(\ell^*) = \inf\{t: A(E(t)) > \ell^*\} 
$$
is equal in distribution to $(-\log F_A(\ell^*))^{-1/\beta} X^{1/\beta} D$,
where $X \sim {\rm Exp}(1)$ and $D$ (defined in \eqref{theD}) are 
independent.

The Mittag-Leffler distribution with parameter $\beta \in (0,1]$ is 
(except for $\beta = 1$) a heavy-tailed positive distribution. 
For $\sigma > 0$, we write ${\rm ML}(\beta, \sigma)$ for the distribution 
of $\sigma Y$, where $Y$ has Laplace transform 
$\mathbf E[\exp(-s Y)] = 1/(1+s^\beta)$. Due to e.g. Theorem 19.1 in 
@Haubold11, the exceedance time from Theorem MS2 can be written as 
\begin{align} \label{eq:hitting-ML}
B(\ell^*) \sim {\rm ML}\left(\beta, (-\log F_A(\ell^*))^{-1/\beta}\right)
\end{align}


# Scaling limit of Exceedance Times

In classical extreme value theory, there are two main approaches for 
the inference on GEV distributions: Block
Maxima and Peaks-Over-Threshold (POT). Block 
Maxima subdivide the time line into 'blocks' of equal length, 
and the maximum of each block is taken as realization of the random 
variable $M_n$. 
This approach is not appropriate for CTRM data, because maxima in 
same-sized blocks will not be i.i.d.
As mentioned in Section 2, the POT approach *does* extract i.i.d. $X(\ell)$ 
(and $T(\ell)$), and can hence be directly used for the inference on 
the extreme values of $J_k$. 
Figure \ref{fig:GP-simulated} shows an example for the so-called 
"threshold-selection" plots for data drawn from the standard Gumbel 
distribution. 
For a range of thresholds, maximum likelihood estimators of the shape and 
scale parameters in the GP distribution are computed and plotted. 
Note that the scale parameter is transformed so that it appears independent
of the threshold [see e.g. Section 4.3.4 in @ColesBook]. 

```{r GPD-simulated-data, warning=FALSE, fig.cap="\\label{fig:GP-simulated}Stability plot for the shape and scale parameters of the generalized Pareto distribution. Here, the magnitudes are standard Gumbel, hence $\\xi = 0$ and $\\sigma = 1$. Plots were generated using the POT package in R [@R-POT]."}
par(mfrow = c(1,2))
JJ <- coredata.ctrm(sim_ctrm)
u.range <- quantile(x = JJ, probs = c(0.75, 0.95))
POT::tcplot(JJ, u.range = u.range)
# extRemes::threshrange.plot(mrp("getMags"), type = "GP", set.panels = FALSE)
```


For the remainder of this article, we focus on statistical inference 
for the inter-exceedance times $T(\ell)$ of the threshold crossings. 
In our setting, the inter-exceedance times follow a fractional 
Poisson process instead of a standard Poisson process, which is how our
approach generalizes the standard POT approach. 

**Theorem:**  

: Let $b(c)$ be the scaling function \eqref{eq:bScale},
and let $\ell$ be a threshold from the support $[x_L, x_R]$ of $J$. 
Furthermore let $p := \mathbf P(J > \ell)$. Under the assumption \eqref{eq:Wscale} and the assumptions of the GEV Theorem, we have 
\begin{equation} \label{eq:Tellscale}
T(\ell) / b(1/p) \to {\rm ML}(\beta, 1) \text{ as } \ell \uparrow x_R.
\end{equation}

*Proof:*
Let the scaling functions $a(c)$ and $d(c)$ be as in Section 
\ref{magnitudes-and-extreme-value-distributions}, and assume WLOG 
$\ell = a(n) \ell^* + d(n)$ for some arbitrary but fixed $\ell^*$, out of the support of $A$. 
We first note that due to \eqref{eq:GEV}
\begin{equation} 
F_J (a(c) \ell^* + d(c))^c \stackrel{d}{\to} F_A(\ell^*), \text{ as } c \to \infty.
\end{equation}
\noindent Taking the logarithm on each side and using the relationship  $z-1 \sim \log(z)$ as $z \to 1$, we get
\begin{equation}
c (1-F_J(a(c) \ell^*+d(c))) \stackrel{d}{\to} - \log F_A(\ell^*).
\end{equation}
\noindent Hence we have 
\begin{equation}
c \cdot p \stackrel{d}{\to} - \log F_A(\ell^*) \label{eq:np_conv}
\end{equation}
\noindent as $\ell \uparrow x_R$.
Now we get
\begin{align}
\begin{split}
\mathbf P \left[T(\ell)/b(1/p) > t \right]
&= \mathbf P[V(b(1/p) t) \leq \ell] \label{eq:proofTheo}
= \mathbf P[V(b(1/p)) \le a(c) \ell^* + d(c)]\\
&= \mathbf P\left(\frac{V(b(1/p)/b(c) \cdot b(c) \cdot t)-d(c)}{a(c)} \le \ell^*\right) \\
&\stackrel{d}{\to} \mathbf P(A(E(-\log F_A(l))^{-1/\beta} t) \leq \ell^*),
\end{split}
\end{align}
where the convergence follows due to Theorem MS1 (with $c$ replaced by $b(c)$) and the fact that
\begin{equation}
\frac{b(1/p)}{b(c)} 
= \frac{b(1/cp \cdot c)}{b(c)} 
\sim (cp)^{-1/\beta}
\to \left( -\log F_A(l)\right)^{-1/\beta} 
\text{ as } c \to \infty.\label{eq:proofTheo2}
\end{equation}
In \eqref{eq:proofTheo2} we used \eqref{eq:np_conv} and 
$b \in RV(1/\beta)$, which means that 
$b(\lambda c) / b(c) \rightarrow \lambda^{1/\beta}$ as 
$c \rightarrow \infty$ uniformly in $\lambda$ on each compact subset of 
$(0,\infty)$. 
The limit in \eqref{eq:proofTheo} is equal to
$$\mathbf P \left( \left( -\log(F_A(\ell^{*})) \right)^ {1/\beta} B(\ell^*) > t\right).$$ 
Due to Theorem MS2 and \eqref{eq:hitting-ML}, we know that 
$(-\log F_A (\ell^*))^{1/\beta} B(\ell^*)$ is $ML(\beta,1)$ distributed, 
and hence the theorem follows. 

**Remark:**

: By the above theorem, the inter-exceedance times are i.i.d. and
approximately Mittag-Leffler distributed, which means that the exceedance
times form a *fractional Poisson process* [@Laskin2003]. 
Since the Mittag-Leffler distribution nests the exponential distribution 
(the special case where $\beta = 1$), the fractional Poisson process 
generalizes the standard Poisson process. 
As the threshold height increases, the threshold crossing events are 
effectively "thinned out", and the thinned (or rarefied) processes retain
the characteristics of a fractional Poisson process [@Gorenflo2010], 
with a growing scale parameter $b(1/p)$.

**Remark:**

: A fractional Poisson process can be represented as a
standard Poisson process $N(t)$, time-changed by an inverse stable 
subordinator $E(t)$ [@Meerschaert2010b]. 
This pattern can be made sense of in our context: 
The exceedance times for a standard extreme value process $A(t)$ form a 
standard Poisson process $N(t)$. Accordingly, the exceedance times 
of the CTRM limit $A(E(t))$ must be $N(E(t))$, a fractional Poisson 
process. 



# Inference on Exceedance times

Equation \eqref{eq:Tellscale} implies that for large $\ell$ we may 
approximate the distribution of $T(\ell)$ with an 
${\rm ML}(\beta, b(1/p))$ distribution.
Building on the POT (Peaks Over Threshold) method, we propose the 
following estimation procedure for the distribution of $T(\ell)$: 

1. For varying thresholds $\ell \uparrow x_R$, extract datasets of
  exceedance times $\{T(\ell, i)\}_i$.
  

2. Fit a Mittag-Leffler distribution to each dataset, which
  results in the $\ell$-dependent estimates $\{\hat\beta(\ell)\}_\ell$ and 
  $\{\hat \sigma(\ell)\}_\ell$.
  

3. Plot $\ell$ vs.\ $\hat \beta(\ell)$. As $\ell$ increases towards $x_R$, 
  $\hat \beta(\ell)$ *stabilizes* around a constant $\hat \beta$. 
  Use $\hat \beta$ as an estimate for the tail parameter $\beta$ of the
  Mittag-Leffler distribution of exceedance times. 
  

4. Approximate $p \approx |\{k: J_k > \ell\}| / n$. 
  Recall that $b(c)$ is regularly varying with parameter $1/\beta$, and 
  hence has the representation $b(c) = L(c) c^{1/\beta}$ for some 
  slowly varying function $L(c)$. 
  Assuming that the variation of $L(c)$ is negligible, we hence 
  plot $\ell$ vs.\ $p^{1/\hat \beta} \hat \sigma(\ell)$. 
  Again as $\ell$ increases towards $x_R$, 
  $p^{1/\hat \beta} \hat \sigma(\ell)$ is expected to stabilize around a constant 
  $\hat \sigma_0$. 
  We then use $p^{-1/\hat \beta} \hat \sigma_0$ as an estimate of the scale 
  parameter of the Mittag-Leffler distribution of exceedance times for
  the level $\ell$. 

The above approach, though theoretically sound, benefits from the following
practical adjustments:

* We choose $\ell$ from the order statistics, i.e. $\ell$ is the $k$-th
  largest of the observations $X_j$, where $k$ runs from 
  $k_\text{min}, k_\text{min} + 1, \ldots, k_\text{max}$. 
  The datasets are then of length $k-1$.
* We use $k$ rather than $\ell$ for the horizontal axis of our plots. 
* In Step 4, rather than plotting $p^{1/\hat \beta} \hat \sigma(\ell)$
  we plot $k^{1/\hat \beta} \hat \sigma(\ell)$. This changes 
  $\hat \sigma_0$ by the multiplicative constant $n^{1/\hat \beta}$, 
  but has the advantage that
  $\hat \sigma_0$ does not change if one pre-processes the data by 
  removing all observations below a certain threshold. 


The estimates $\hat \beta$ and $\hat \sigma_0$ give an estimate of the 
distribution of exceedance times, dependent on the threshold $\ell$:
\begin{align*}
T(\ell) \sim {\rm ML}(\hat \beta, k^{-1/\hat \beta} \hat \sigma_0).
\end{align*}
For quick estimates of the Mittag-Leffler parameters the method of
log-transformed moments by @Cahoy2013 was used.


# Checking Model Assumptions 

The CTRM model is based on three main assumptions, which are repeated 
below. For each assumption, we suggest one means of checking if it holds: 

I.i.d.:
: The pairs $(W_i, J_i)$ are i.i.d. An indication if this is true is given 
  by an auto-correlation plot for the logarithms (to ensure finite moments) 
  of the two time series.
  
  

Uncoupled:
: Each $W_i$ is independent of each $J_i$. We propose an empirical copula
  plot to check for any dependence. 
  
  

Heavy tails:
: The waiting times are heavy-tailed with tail parameter 
  $\beta \in (0,1)$. A Hill plot can confirm this assumption. 


The motivation behind a CTRM model is to fit extreme observations
and their inter-arrival times. 
Observations below a certain threshold may be interpreted as noise and 
discarded.
Since the signal rather than the noise needs to satisfy our modelling 
assumptions, we suggest that the above model assumptions are checked 
*after* the noisy small observations are discarded. 


# Application to data

## Simulated Data

To test our inference method, we have simulated `r params$n` 
independent
waiting time and magnitude pairs $(W_k, J_k)$. In order to have exact 
analytical values available for $\beta$ and $\sigma_0$, a distribution for 
$W_k$ needs to be chosen for which $b(n)$ from \eqref{eq:Wscale} is known. 
If we choose $W_k \stackrel{d}{=} D$, where $D$ is as in \eqref{theD}, 
then due to the stability property we have the *equality* of distribution
$W_1 + \ldots + W_n \stackrel{d}{=} b(n) D$, 
for $b(n) = n^{1/\beta}$. 
Using the parametrisation of @SamorodnitskyTaqqu, a few lines of 
calculation (see e.g. the vignette on parametrisation in @MittagLeffleR) 
show that $D$ must have the stable distribution 
$S_\beta(\cos(\pi \beta/2)^{1/\beta}, +1, 0)$, which is 
implemented in the R package `stabledist` by @stabledist. 

```{r simulated-example, message=FALSE, fig.cap="\\label{fig:sim}Tail and scale estimates for simulated data, with waiting times drawn from the stable distribution $S_\\beta(\\cos(\\pi \\beta/2)^{1/\\beta}, +1, 0)$ with $\\beta = 0.8$. Dashed lines are 95% confidence intervals, dotted lines are the known theoretical values ($0.8$ and $10000^{1/0.8}$)."}
k_max <- 500 
thin_sim_ctrm <- thin(ctrm = sim_ctrm, k = k_max)
par(mfrow=c(1,2))
MLestimates(ctrm = thin_sim_ctrm, tail = tail, scale = n^(1/tail))
```

By \eqref{eq:Tellscale}, the distribution 
of $T(\ell)$ is approximately 
${\rm ML}(\beta, p^{-1/\beta}) 
= {\rm ML}(\beta, k^{-1/\beta} n^{1/\beta})$, which means 
$\sigma_0 = n^{1/\beta}$.
The distribution of $J_k$ is irrelevant for the inference on $\beta$ and 
$\sigma_0$ (we have chosen unit exponential random variables). 
Figure \ref{fig:sim} displays plots of $\hat \beta(\ell)$ and 
$\hat \sigma(\ell)$ vs. $k$, the number of exceedances as $\ell$ traverses 
the largest observations $J_i$. 
Dotted lines show 95% confidence intervals, which are derived from the 
asymptotic normality of the log-moments estimators [@Cahoy2013] and the $\delta$-method [@MittagLeffleR].
The dashed lines show the actual values of $\beta$ resp.\ $\sigma_0$, 
showing that our inference method effectively identifies the 
right parameters. 


## Bitcoin trading volumes

```{r bitcoin-data, fig.cap="\\label{fig:bitcoin-data}Time Series of 'Bitcoin days destroyed', a measure for the traded volume of bitcoins."}
bitcoin_ctrm <- ctrm(bitcoin)
plot(bitcoin_ctrm, p = 0.02)
```


We study the daily trade volumes of Bitcoin since 2009, provided by 
Blockchain and downloaded from Data 
Market\footnote{\url{https://datamarket.com/data/list/?q=provider:blockchain}}. 
Although the observations are regular (daily), extremes in the trade volumes
occur in bursts, which can be seen over timescales of months and years 
(Figure \ref{fig:bitcoin-data}). 

```{r bitcoin-data-tail-scale, message=FALSE, fig.cap="\\label{fig:bitcoin-tail-scale}Tail and scale plot of the bitcoin data."}
thin_bitcoin_ctrm <- thin(ctrm = bitcoin_ctrm, k = 250)
par(mfrow=c(1,2))
MLestimates(thin_bitcoin_ctrm, tail = 0.9, scale = 2 * 1E3)
```

Figure \ref{fig:bitcoin-tail-scale} shows plots identifying the candidates
$\beta = 0.9$ and $\sigma_0 = 2000$ for 
the tail and scale parameters of the exceedance time distribution. 
That is, exceedances of a threshold $\ell$ at the $k$-th largest observed 
magnitude are distributed as 
$$T(\ell) = \text{ML}(0.9, 2000 * k^{-1/0.9}).$$ 
A QQ plot (Figure \ref{fig:bitcoin-diag}) of the exceedance times at the 
level of the 200th 
largest event lends credence to a heavy-tailed distribution with tail
parameter near the value $1$. 


## Solar Flare Data

```{r solar-flare-data, fig.cap="\\label{fig:solar-flare-data}The solar flare time series data."}
flares_ctrm <- ctrm(flares)
plot(flares_ctrm, p = 0.01)
```



The "complete Hard X Ray Burst Spectrometer event list" 
\footnote{\url{https://umbra.nascom.nasa.gov/smm/hxrbs.html}} 
@HXRBS is a 
comprehensive reference for all measurements of the Hard X 
Ray Burst Spectrometer on NASA's Solar Maximum Mission from the time of 
launch on Feb 14, 1980 to the end of the mission in Dec 1989. 12,776 
events were detected, with the "vast 
majority being solar flares". The list includes the start time, peak time, 
duration, and peak rate of each event. We have used "start time" as the 
variable for event times, and "peak rate" as the variable for event 
magnitudes (Figure \ref{fig:solar-flare-data}). 

```{r solar-flare-tail-scale, message=FALSE, fig.cap="\\label{fig:flares}Stability plots for the tail and scale parameter of the Mittag-Leffler distribution of the Solar Flare dataset."}
thin_flares_ctrm <- thin(ctrm = flares_ctrm, k = 150)
par(mfrow=c(1,2))
MLestimates(thin_flares_ctrm, tail = tail, scale = 2.5 * 1E7)
```

Figure \ref{fig:flares} shows the fitted tail and scale parameters 
of the Mittag-Leffler distribution. The dotted line for the tail 
parameter is at $\beta = 0.85$, yielding the plot of (transformed) scale 
estimates $\hat \sigma_0 = k^{1/0.85} \hat \sigma(\ell)$. 
We suggest the estimate $\sigma_0 = 2.5 \times 10^7$ seconds 
$\approx 289$ days. 
The exceedance times of a threshold $\ell$ as high as the $k$-measurement 
are hence Mittag-Leffler distributed as
$$ T(\ell) \sim {\rm ML}(0.85, 289  k^{-1/0.85} \text{ days}).$$


# Discussion

Comparing plots of the simulated data in Figure \ref{fig:thresholdedBursty}
with plots of the 
empirical data \ref{fig:bitcoin-data} and \ref{fig:solar-flare-data}, 
it can be seen that the empirical data show long time intervals without 
*any* event occurring, whereas for real-world data events appear to happen 
continuously. 
This seeming discrepancy vanishes, however, when all but the $k_\text{max}$
largest observations are discarded. 
We repeat that the CTRM model focuses on extreme events and interprets 
smaller events as noise. 

The CTRM model, moreover, assumes a "pure" power-law for the event 
inter-arrival times. 
Real datasets, however, are often exponentially 
tapered or truncated, see e.g. the discussion of tempered power-law 
distributions by @MeerschaertRoyQin and the truncated Pareto distribution 
by @Aban06. 
This means that the fit to a power-law
distribution may seem adequate for medium-size time scales, 
but that at very large time-scales the power-law character of the 
distribution can weaken or disappear.
This behaviour seems to appear in both the Bitcoin data and the Solar-Flare
data: the Hill plot for the tail parameter is increasing towards lighter
tails as the threshold reaches very high values. 
This may mean that the CTRM model may overestimate the heaviness of the
tail of the waiting time distribution; or that a CTRM base on a *tempered* 
power-law renewal process might be a more realistic model. 

# Conclusion

We have proposed the CTRM model for the extremes of "bursty" events. 
Burstiness is a phenomenon of intermittency which has received a lot of 
attention in the recent statistical physics literature. 
The CTRM model is a straightforward generalization of the POT (Peaks over 
Threshold) model, for which the inter-arrival times between threshold 
crossings are exponentially distributed. 
If the Mittag-Leffler tail parameter of the CTRM equals $1$, then the 
CTRM model reproduces this behaviour exactly, showing that the CTRM model 
nests the POT model. 

The scale parameter $\sigma$ of the inter-event distribution follows a 
power-law $\sigma \propto p^{-1/\beta}$, where $\beta \in (0,1)$ is the 
tail parameter of the inter-event distribution and $p$ the probability 
that an event crosses a given threshold. 
From this power law, we have constructed "stability plots", from which 
estimates of $\beta$ and $\sigma$ can be read off. 

We have demonstrated the applicability of the CTRM model with two 
real-world datasets. 
Although the CTRM model possibly overestimates the heaviness of the tail 
of the inter-arrival distribution, it clearly captures that 
the inter-arrival times of threshold crossings scale non-linearly with 
the treshold crossing probability, and follow a clearly non-Poissonian 
behaviour. 
Thus we have shown that the CTRM model is a useful tool for the modelling 
of extremes of bursty events, which requires very little computation and 
which allows for straightforward ways of checking and criticizing model 
assumptions. 
The analyses from this paper are readily reproduced via the R package 
`CTRM`, available at \url{https://github.com/strakaps/CTRM}. 

## Acknowledgements

The authors would like to thank Peter Scheffler for insights on 
stochastic process limits for CTRMs, and Gurtek Gill who helped create
the MittagLeffleR R-package. 

\appendix

# Diagnostic Plots

```{r simulated-diag, fig.width=5, fig.height=7.5, fig.cap="\\label{fig:simulated-diag}Diagnostic plots for the simulated data."}
par(mfrow=c(3,2))
diagnostics(thin_sim_ctrm, tail = tail)
```


```{r bitcoin-diag, fig.width=5, fig.height=7.5, fig.cap="\\label{fig:bitcoin-diag}Diagnostic plots for the Bitcoin data."}
par(mfrow=c(3,2)) 
diagnostics(ctrm = thin_bitcoin_ctrm, tail = 0.9)
```

```{r solar-flare-diag, fig.width=5, fig.height=7.5, fig.cap="\\label{fig:solar-flar-diag}Diagnostic plots for the Solar Flare data."}
par(mfrow=c(3,2))
diagnostics(thin_flares_ctrm, tail = 0.85)
```


\newpage

