---
title: Inference for Heavy-Tailed Max-Renewal Processes

# to produce blinded version set to 1
blinded: 0

authors: 
- name: "Katharina Hees"
  thanks: The authors gratefully acknowledge ...
  affiliation: University of Dortmund
  
- name: "Smarak Nayak"
  affiliation: National Australia Bank
  
- name: "Peter Straka"
  affiliation: UNSW Sydney
  
keywords:
- heavy tails

- renewal process

- extreme value theory

- peaks over threshold

abstract: |
  Max-renewal processes, or Continuous Time Random Maxima, assume that
  events arrive according to a renewal process, and track the running
  maximum of the magnitudes of events up to time $t$.  In many complex
  systems of interest, notably earthquakes, trades and neuron voltages,
  inter-arrival times exhibit heavy-tailed distributions. The dynamics of
  events then exhibits memory, which affects the rate at which events
  occur: rates are highly variable in some time intervals, while other
  intervals have long quiescent periods, a behaviour which has been dubbed 
  "bursty" in the physics literature. 
  
  This article provides a statistical model for the exceedances $X(\ell)$
  and inter-exceedance times $T(\ell)$ of events whose magnitude exceeds a
  given threshold $\ell$. It derives limit theorems for the distribution of
  $X(\ell)$ and $T(\ell)$ as $\ell$ approaches very high values: as is
  well-known, $X(\ell)$ approaches a generalized Pareto distributions; we
  moreover show that $T(\ell)$ approaches a Mittag-Leffler distribution
  whose scale parameter increases as $\ell^{1/\beta}$, where $\beta \in (0,1)$
  is the exponent of the inter-arrival distribution of events. We provide
  graphical means of estimating model parameters, and show that these
  methods provide useful results on a simulated dataset, as well as
  Earthquake, Trading and Solar Flare data. 

bibliography: CTRMstats.bib

output: rticles::asa_article

# doesn't seem to work

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, cache = TRUE, message = FALSE)
```


# Introduction

Time series displaying temporally inhomogeneous behaviour have received 
strong interest in the recent statistical physics literature 
[@Barabasi2005, @Oliveira2005, @Vasquez2006, @Vazquez2007, @Omi2011, 
@Min2010, @Karsai2011, @Bagrow2013], and have been observed in the context 
of earthquakes, sunspots, neuronal activity and human communication (see 
@Karsai2012, @Vajna2013 and @MeerschaertStoev08 for a list of references. 
Such time series exhibit high activity in some 'bursty' intervals, which 
alternate with other, quiet intervals.  Although several mechanisms are 
plausible explanations for bursty behaviour (most prominently self-exciting
point processes [@hawkes1971point]), there seems to be one salient feature 
which very typically indicates the departure from temporal homogeneity: a 
heavy-tailed distribution of waiting times [@Vasquez2006, @Karsai2012, 
@Vajna2013]. As we show below in simulations, a simple renewal process with
heavy-tailed waiting times can capture this type of dynamics. For many 
systems, the renewal property is appropriate; a simple test of the absence 
of correlations in a succession of waiting times can be undertaken by 
randomly reshuffling the waiting times [@Karsai2012].

Often a magnitude can be assigned to each event in the renewal process, 
such as for earthquakes, sun flares or neuron voltages. It is then natural 
to study the size and timing of the largest events. Thus two questions that
arise are: 
When will the next extreme event occur? And, how large will it be?
A probabilistic extreme value model which assumes the renewal property can 
be used to answer these questions. One such model has been studied under 
the names "Continuous Time Random Maxima process" (CTRM) 
[@Benson2007, @MeerschaertStoev08, @Hees16, @Hees17], 
"Max-Renewal process" [@Silvestrov2002a, @ST04, @Basrak2014], 
and "Shock process"
[@Esary1973, @Sumita1983, @Sumita1984, @Sumita1985, @Anderson1987, @Gut1999].
In this work, we discuss ideas for methods of inference for this type of 
model, a problem which has seemingly received little attention by the 
statistical community.
We give introduce the CTRM, or max-renewal model, in Section 2, and 
derive a scaling limit theorem for inter-exceedance times in Sections 3 &
4. 
A statistical procedure to estimate model parameters via stability plots 
is outlined in Section 5, and diagnostic plot for model criticism are 
discussed in Section 6. 
In Section 7, we give case studies for simulated data as well as for two
real-world datasets, with a discussion in Section 8. 
All statistical computations have been done in R, and all code, data, as 
well as the source code for this manuscript has been organized into an R 
software package, available at 
\url{https://github.com/strakaps/CTRM}. 


# CTRMs

In this section we will introduce the Continuous Time Random Maxima process
as well its exceedance and corresponding exceedance time. Additionally we 
will recall some results from classical extreme value theory, which are 
important for the rest of the article. 

Continuous Time Random Maxima (CTRM), or Max-Renewal processes, track the 
largest event in a renewal sequence of events [@Basrak2014, 
@MeerschaertStoev08, @Hees16]:

Definition (CTRM): 

: Let $(W,J), (W_1, J_1), (W_2, J_2), \ldots$ be i.i.d. pairs of random 
variables, where the $W_k > 0$ are interpreted as the *waiting times* or 
inter-arrival times and $J_k \in [x_L, x_R]$ as the *event magnitudes* 
($x_L \in [-\infty, +\infty), x_R \in (-\infty, +\infty]$). 
The renewal process associated with the $W_k$ is 
$$N(t) = \max\{n: W_1 + \ldots + W_n \le t\},$$
and the running maximum is $M(n) := \bigvee_{k=1}^n J_k$. Then the process
$$V(t)=M(N(t)) = \bigvee_{k=1}^{N(t)} J_k, \quad t \ge 0.$$
is called a CTRM (Continuous Time Random Maxima) process. 
If $W$ and $J$ are independent, the CTRM is said to be *uncoupled*. 
We let $M(0) = x_L$.

![\label{fig:ctrm} A CTRM sample path.](just-tikz-figure0.pdf)

It follows from the definition of the CTRM $V(t)$, that its paths are
non-decreasing, piece-wise constant and right-continuous, see figure 
\ref{fig:ctrm}.

The main purpose of this article is to provide a method for fitting data to
a CTRM. Therefore we will first study the distribution of the following two
random variables:

Definition: 

: The random variables
$$X(\ell) = V(T(\ell)) - \ell, \quad 
T(\ell) = \inf\{t: V(t) > \ell\}, 
\quad \ell \in (x_L, x_R)$$
are called the *exceedance* resp. *time until exceedance* of level $\ell$.


It is clear that $T(\ell)$ assumes values in the renewal set 
$\{\sum_{k=1}^n W_k: n \ge 0\}$, the time points at which new events occur.
Applying the renewal property at $T(\ell)$ (i.e. ``resetting'' the clock to
$0$) then yields another CTRM process based on the pair-sequence 
$(W_{\tau(\ell)+1}, J_{\tau(\ell)+1}), (W_{\tau(\ell)+2}, J_{\tau(\ell)+2}), \ldots$ started at $\tau(\ell) = \min\{k: J_k > \ell\}$,
where T(l,k) is the  This new CTRM process has the same distribution as the
original CTRM $V(t)$. By repetition, we can construct i.i.d.\ sequences
$\{T(\ell,k)\}_{k}$ and
$\{X(\ell,k)\}_{k}$ for any given threshold $\ell$.
Moreover, in the uncoupled case we observe: since $J_{\tau(\ell)}$ is
independent of the $\sigma$-algebra generated by
$W_1, W_2, \ldots, W_{\tau(\ell)}$, the two random variables
$X(\ell) = J_{\tau(\ell)}$ and
$T(\ell) = W_1 + \ldots + W_{\tau(\ell)}$ are independent.




```{r thresholdedBursty, message=FALSE, fig.cap="\\label{fig:thresholdedBursty}Exceedances (red) and Times until Exceedance (durations between blue crosses) for a given threshold $\\ell$ (dashed line)."}
library(CTRM)
times <- cumsum(MittagLeffleR::rml(n = 1000, tail = 0.8, scale = 5))
magnitudes <- rexp(n = 1000)
mrp <- new_mrp(times, magnitudes)
plot(mrp)
```


Figure \ref{fig:thresholdedBursty} illustrates that $T(\ell, k)$ and 
$X(\ell, k)$ are directly observable in data: Event magnitudes $J_k$ are 
grey vertical lines at their arrival times $W_1 + \ldots + W_k$. 
Thresholding at a level $\ell$ (dashed line) gives a series of 
$\{X(\ell,k)\}_{k}$ (red) and the preceding times until exceedance 
$\{T(\ell, k)\}_{k}$ (distances between adjacent blue crosses).


A standard result from extreme value theory provides the asymptotic 
distribution of $X(\ell)$ as $\ell \uparrow x_R$. For later use, we also 
include the scaling limit of the cumulative maximum $M(n)$. 

**Theorem GEV** (e.g. Chapter 2 & Section 5.3, @beirlantBook):

Suppose the distribution of $J_k$ is continuous. Then there
exist non-decreasing norming functions $a(n)$ and $d(n)$ such that
as $n \to \infty$, the running maximum $M(n)$ converges weakly 
to a *Generalized Extreme Value Distribution* with shape
parameter
$\xi$:
$$[M(n) - d(n)] / a(n) \stackrel{d}{\to} A, 
\quad
\mathbf P(A \le z) = G(z | \xi) = \exp\left(-[1+\xi z]^{-1/\xi}\right),$$
defined for $z$ such that $1 + \xi z > 0$. 
This definition extends continuously to $\xi = 0$ via 
$$G(z | 0) = \exp(-\exp(-x)).$$
For $\mu$ and $\sigma > 0$, we write ${\rm GEV}(\xi, \mu, \sigma)$ for the 
probability distribution of the random variable $\sigma A + \mu$. 

Moreover, asymptotically as $\ell \uparrow x_R$,
$$\mathbf P(J - \ell > y | J > \ell) 
\to 1 - H(y),$$
where 
$$H(y) = \begin{cases}
1 - (1+ \xi y / \tilde \sigma)^{-1/\xi}, & y \in (0,\infty) \text{if } \xi > 0,\\
1 - \exp(-y/\tilde \sigma), & y \in (0,\infty) \text{if } \xi = 0,\\
1 - (1+ \xi y / \tilde \sigma)^{-1/\xi}, & y \in (0, -\sigma / \xi) \text{if } \xi < 0
\end{cases}$$

where $\tilde \sigma := \sigma + \xi(\ell-\mu)$.
The CDF $H(y)$ belongs to the *Generalised Pareto family*
$GP(\xi,\bar \sigma)$.


# CTRM Scaling limits

## Waiting times

We will assume that the waiting times $W_k$ have very heavy tails,
i.e.~a tail parameter $\beta \in (0,1)$ and regularly varying tail probabilities:
$\mathbf P(W > t) \sim L(t) t^{-\beta}$ as $t \uparrow \infty$ for
some slowly varying function $L(t)$. As usually, $f(t) \sim g(t)$
means that the quotient of $f(t)$ and $g(t)$ converges to $1$. The
law of the $W$ then lies in the domain of attraction of a stable law,
in the sense that the distributional limit 
\begin{align} \label{eq:Wscale}
\frac{W_1 + \ldots + W_n}{b(n)} \overset{d}{\longrightarrow} D, 
\quad n \to \infty
\end{align}
exists, for a regularly varying scaling function
\begin{equation} \label{eq:bScale}
b \in {\rm RV}_\infty(1/\beta)
\end{equation}
[Sec. 2.9.2, @beirlantBook]. 
The limit is then a positively skewed stable distribution, 
whose scale parameter is $1$ if $b(n)$ is chosen accordingly, i.e. \begin{align} \label{theD}
\mathbf E[\exp(-sD)] = \exp(-s^\beta)
\end{align}
Moreover, the following functional limit theorem holds: \[
(W_1 + \ldots + W_{\lfloor ct \rfloor})/b(c) \overset{d}{\longrightarrow} D(t), \quad c \to \infty
\] with convergence in the Skorokhod $J_1$ topology. The limit
$D(t)$ is a stable subordinator, i.e.~an increasing LÃ©vy process with
Laplace transform $\exp(-t s^\beta)$.


It is well known [see e.g. @limitCTRW] that the renewal
process then satisfies the functional limit
$$
N(ct)/ \tilde b(c) \stackrel{d}{\to} E(t) = \inf\{r: D(r) > t\}, 
\quad c \to \infty
$$
for a scaling function $\tilde b(c) \in {\rm RV}_\infty(\beta)$ which is asymptotically inverse to $b(c)$, in the sense of @seneta (p.20): 
$$
b(\tilde b(c)) \sim c \sim \tilde b(b(c)).
$$
[see e.g. Prop 4.15 in @MeerschaertSikorskii]. 
The limit process $E(t)$ is called the _inverse stable subordinator_ [@invSubord].

## Magnitudes and Extreme Value Distributions

The extremal limit theorem then allows for an extension to functional (pathwise) limits: assume that the norming sequences $a(n)$ and $d(n)$ are as in Theorem GEV. Then 
$$
[M(\lfloor ct \rfloor) - d(c)] / a(c) \stackrel{d}{\to} A(t),
\quad c \to \infty.
$$
Convergence is in Skorokhod's $J_1$ topology, and the limit
process $A(t)$ is an _extremal process_, with
finite-dimensional distributions given by
$$
\mathbf P(A(t_i)\leq x_i,1\leq i \leq d) 
= F_A(\wedge_{i=1}^d x_i)^{t_1} 
F_A(\wedge_{i=2}^d x_i)^{t_2-t_1}
\ldots F_A(x_d)^{t_d-t_{d-1}},
$$
where $F_A(x)$ is a GEV distribution. 

## CTRM limit

The CTRM $V(t)$ results from the running maximum $M(n)$ via a time change by the renewal process $n = N(t)$. This is also reflected in its corresponding limit process:

Theorem MS1 [@MeerschaertStoev08]: 

: The CTRM process $V(t) = M(N(t))$ satisfies the following functional scaling limit in the Skorokhod $J_1$ topology: 
$$
[V(ct) - d(\tilde b(c))] / a(\tilde b(c)) \stackrel{d}{\to} 
A(E(t)), \quad c \to \infty.
$$

The distribution of the _hitting time_ of a level $\ell^*$ by the limit 
process $A(E(t))$ is also known:

Theorem MS2 [@MeerschaertStoev08]: 

: Let $F_A$ be the CDF of a GEV distribution, and let $A(t)$ be the
corresponding extremal process. 
For a given threshold $\ell^*$ in the support of $F_A$,
the hitting time
$$
B(\ell^*) = \inf\{t: A(E(t)) > \ell^*\} 
$$
is equal in distribution to $(-\log F_A(\ell^*))^{-1/\beta} X^{1/\beta} D$,
where $X \sim {\rm Exp}(1)$ and $D$ (defined above) are independent.

The Mittag-Leffler distribution with parameter $\beta \in (0,1]$ is 
(except for $\beta = 1$) a heavy-tailed positive distribution. 
For $\sigma > 0$, we write ${\rm ML}(\beta, \sigma)$ for the distribution 
of $\sigma Y$, where $Y$ has Laplace transform 
$\mathbf E[\exp(-s Y)] = 1/(1+s^\beta)$. Due to e.g. Theorem 19.1 in 
@Haubold11, the exceedance time from Theorem MS2 can be written as 
$$
B(\ell^*) \sim {\rm ML}\left(\beta, (-\log F_A(\ell^*))^{-1/\beta}\right)
$$


# Scaling limit of Exceedance Times

There are two main approaches in classical extreme value theory : the Block
Maxima method and the Peak-Over-Threshold (POT) approach. For the Block 
Maxima method, the time line gets subdivided in `Blocks` of equal length 
and the maximum of each block is taken as realization of the random 
variable $M_n$. An approach where on subdivides the time-line is for our 
model inappropriate, since different choices of subdivision would lead to 
different results, since we assume random waiting times between our 
magnitudes and want to use our model to analyze irregular arising events. 
For the POT  approach, one chooses a threshhold $l$ and due to Theorem 3 
the distribution of the exceedances is known, which is a GPD distribution. 
So one can then fit data by estimating the parameters of a GPD. The method 
which we present in this article is similar to the POT approach, except 
that we have to take the random waiting times between the jumps into 
account. To do so, we need additionally the assymptotic distribution of the
exceedance time, which delivers the following theorem.

**Theorem**  

Let $b(c)$ be the scaling function \eqref{eq:bScale},
and let $\ell$ be a threshold from the support $[x_L, x_R]$ of $J$. 
Furthermore let $p := \mathbf P(J > \ell)$. Under the assumption \eqref{eq:Wscale} and the assumptions of the GEV Theorem, we have 
\begin{equation} \label{eq:Tellscale}
T(\ell) / b(1/p) \stackrel{d}{\to} {\rm ML}(\beta, 1), \quad \ell \uparrow x_R.
\end{equation}

*Proof:*
Let the scaling functions $a(c)$ and $d(c)$ be as in Section 
\ref{magnitudes-and-extreme-value-distributions}, and assume WLOG 
$\ell = a(n) \ell^* + d(n)$ for some arbitrary but fixed $\ell^*$, out of the support of $A$. 
We first note that due to \eqref{eq:GEV}
\begin{equation} 
F_J (a_n \ell^* + d_n)^n \stackrel{d}{\to} F_A(\ell^*), \text{ as } n \to \infty.
\end{equation}
\noindent Taking the logarithm on each side and using the relationship  $z-1 \sim \log(z)$ as $z \to 1$, implies
\begin{equation}
n (1-F_J(a_n \ell^*+d_n)) \stackrel{d}{\to} - \log F_A(\ell^*).
\end{equation}
\noindent Hence we have 
\begin{equation}
n \cdot p \stackrel{d}{\to} - \log F_A(\ell^*) \label{eq:np_conv}
\end{equation}
\noindent as $\ell \uparrow x_R$.
Now we get
\begin{align}
\mathbf P \left(T(\ell)/b(1/p) > t \right) &= P(M(b(1/p) t) \leq \ell) \label{eq:proofTheo}\\
&= \mathbf P\left(\frac{V(b(1/p)/b(c) \cdot b(c) \cdot t)-d((b(c)))}{a(b(c))} \le \ell^*\right) \nonumber\\
&\stackrel{d}{\to} \mathbf P(A(E(-\log F_A(l))^{-1/\beta} t) \leq \ell^*),\nonumber
\end{align}
where the convergence follows due to Theorem MS1 and the fact that
\begin{equation}
b(1/p)/b(c) = b(1/cp \cdot c) \to \left( -\log F_A(l)\right)^{-1/\beta} \text{ as } c \to \infty,
\end{equation}
where we used that $b \in RV(1/\beta)$ and \eqref{eq:np_conv}. The right side of \eqref{eq:proofTheo} is equal to
$$\mathbf P \left( \left( -\log(F_A(\ell^{*})) \right)^ {1/\beta} B(\ell^*) > t\right).$$ Due to Theorem MS2 and the scaling proparty of the Mittag Leffler distribution we know that $(-\log F_A (\ell^*))^{1/\beta} B(\ell^*)$ is $ML(\beta,1)$ distributed, hence the assertion follows. 


# Inference on Exceedance times

Equation \eqref{eq:Tellscale} implies that for large $\ell$ we may 
approximate the distribution of $T(\ell)$ with an 
${\rm ML}(\beta, b(1/p))$ distribution.
Inspired by the POT (points over threshold) method, one may use the 
following estimation procedure for the distribution of $T(\ell)$: 

1. For varying thresholds $\ell \uparrow x_R$, extract datasets of
  exceedance times $\{T(\ell, k)\}_k$.
  

2. Fit a Mittag-Leffler distribution to each dataset, which
  results in the $\ell$-dependent estimates $\{\hat\beta(\ell)\}_\ell$ and 
  $\{\hat \sigma(\ell)\}_\ell$.
  

3. Plot $\ell$ vs.\ $\hat \beta(\ell)$. As $\ell$ increases towards $x_R$, 
  $\hat \beta(\ell)$ *stabilizes* around a constant $\hat \beta$. 
  Use $\hat \beta$ as an estimate for the tail parameter $\beta$ of the
  Mittag-Leffler distribution of exceedance times. 
  

4. Approximating $p \approx |\{k: J_k > \ell\}| / n$, 
  plot $\ell$ vs.\ $p^{1/\hat \beta} \hat \sigma(\ell)$. 
  Again as $\ell$ increases towards $x_R$, 
  $p^{1/\hat \beta} \hat \sigma(\ell)$ stabilizes around a constant 
  $\hat \sigma_0$. 
  Use $p^{-1/\hat \beta} \hat \sigma_0$ as an estimate of the scale 
  parameter of the Mittag-Leffler distribution of exceedance times for
  the level $\ell$. 
  

For a more practicable algorithm, we make the following adjustments to the
above four steps: 

* We choose $\ell$ from the order statistics, i.e. $\ell$ is the $k$-th
  largest of the observations $X_j$, where $k$ runs from 
  $k_\text{min}, k_\text{min} + 1, \ldots, k_\text{max}$. 
  The datasets are then of length $k-1$.
* We use $k$ rather than $\ell$ for the horizontal axis of our plots. 
* In Step 4, rather than plotting $p^{1/\hat \beta} \hat \sigma(\ell)$
  we plot $k^{1/\hat \beta} \hat \sigma(\ell)$. This changes 
  $\hat \sigma_0$ by a multiplicative constant, but has the advantage that
  $\hat \sigma_0$ does not change if one pre-processes the data by 
  removing all observations below a certain threshold. This is discussed
  further below. 


The estimates $\hat \beta$ and $\hat \sigma_0$ give an estimate of the 
distribution of exceedance times, dependent on the threshold $\ell$:
\begin{align*}
T(\ell) \sim {\rm ML}(\hat \beta, k^{-1/\hat \beta} \hat \sigma_0).
\end{align*}
For quick estimates of the Mittag-Leffler parameters the method of
log-transformed moments by @Cahoy2013 was used.


# Checking Model Assumptions 

The CTRM model is based on three main assumptions, which are repeated 
below. For each assumption, we suggest one means of checking if it holds: 

I.i.d.:
: The pairs $(W_i, J_i)$ are i.i.d. An indication if this is true is given 
  by a cross-correlation plot for the two time series.
  
  

Uncoupled:
: Each $W_i$ is independent of each $J_i$. We propose an empirical copula
  plot to test independence. 
  
  

Heavy tails:
: The waiting times are heavy-tailed with tail parameter 
  $\beta \in (0,1)$. A Hill plot can confirm this assumption. 


It is important to observe that our statistics remain the same if all 
observations smaller than the $k_\text{max}$-largest observation are 
**discarded**. 
In the same vain, the above model assumptions need, from a 
theoretical point of view, only apply to the not discarded data; 
in other words, the aim of a CTRM model is to fit the extreme observations
and their inter-arrival times. 
We hence propose to produce the above three model-checking plots for the 
dataset containing the $k_\text{max}$ largest observations only. 


# Application to data

## Simulated Data

To test our inference method, we have simulated $n=10000$ independent
waiting time and magnitude pairs $(W_k, J_k)$. In order to have exact 
analytical values available for $\beta$ and $\sigma_0$, a distribution for 
$W_k$ needs to be chosen for which $b(n)$ from \eqref{eq:Wscale} is known. 
If we choose $W_k \stackrel{d}{=} D$, where $D$ is as in \eqref{theD}, 
then due to the stability property we have the *equality* of distribution
$W_1 + \ldots + W_n \stackrel{d}{=} b(n) D$, 
for $b(n) = n^{1/\beta}$. 
Using the parametrisation of @SamorodnitskyTaqqu, a few lines of 
calculation (see e.g. the vignette on parametrisation in @MittagLeffleR) 
show that $D$ must have the stable distribution 
$S_\beta(\cos(\pi \beta/2)^{1/\beta}, +1, 0)$, which is 
implemented in the R package `stabledist` by @stabledist. 

```{r simulated-example, message=FALSE, fig.cap="\\label{fig:sim}Tail and scale estimates for a simulated simulated data, with waiting times drawn from the stable distribution $S_\\beta(\\cos(\\pi \\beta/2)^{1/\\beta}, +1, 0)$ and unit exponentially distributed magnitudes. Dashed lines are 95% confidence intervals, dotted lines are the known theoretical values.", cache = TRUE}
tail <- 0.65
n <- 10000
k_max <- 400
rescale <- (n/k_max)^(1/tail)
sigma <- (cos(pi*tail/2))^(1/tail) / rescale
times <- cumsum(stabledist::rstable(n, tail, 1, sigma, pm=1))
magnitudes <- rexp(n)
mrp <- new_mrp(times, magnitudes)
mrp <- mrp("thin", k = k_max)
par(mfrow=c(1,2))
plot(mrp, what = "MLtail", hline = tail)
plot(mrp, what = "MLscale", tail = tail, hline = n)
```

By Theorem \ref{eq:Tellscale}, the distribution 
of $T(\ell)$ is approximately ${\rm ML}(\beta, p^{-1/\beta})$, which means 
$\sigma_0 = 1$.
The distribution of $J_k$ is irrelevant for the inference on $\beta$ and 
$\sigma_0$; we have chosen unit exponential random variables. 
Figure \ref{fig:sim} displays plots of $\hat \beta(\ell)$ and 
$\hat \sigma(\ell)$ vs. $k$, the number of exceedances as $\ell$ traverses 
the largest observations $J_i$. 
Dotted lines show 95 % confidence intervals, which are derived from the 
asymptotic normality of the log-moments estimators [@Cahoy2013] and the $\delta$-method [@MittagLeffleR].
The dashed lines show the actual values of $\beta$ resp.\ $\sigma_0$, 
showing that our inference method effectively identifies the 
right parameters. 


## Bitcoin trading volumes

```{r bitcoin-data, fig.cap="\\label{fig:bitcoin-data}Time Series of 'Bitcoin days destroyed', a measure for the traded volume of bitcoins."}
library(zoo)
times <- as.double(time(bitcoin))
mags <- coredata(bitcoin)
bitcoin_mrp <- new_mrp(times, mags)
plot(bitcoin_mrp, p = 0.02)
```


We study the daily trade volumes of Bitcoin since 2009, provided by 
Blockchain and downloaded from Data 
Market\footnote{\url{https://datamarket.com/data/list/?q=provider:blockchain}}. 
Although the observations are regular (daily), extremes in the trade volumes
occur in bursts, which can be seen over timescales of months and years 
(Figure \ref{fig:bitcoin-data}). 

```{r bitcoin-data-tail-scale, message=FALSE, fig.cap="\\label{fig:bitcoin-tail-scale}Tail and scale plot of the bitcoin data."}
bitcoin_mrp <- bitcoin_mrp("thin", k = 250)
par(mfrow=c(1,2))
plot(bitcoin_mrp, what = "MLtail", hline = 0.9)
plot(bitcoin_mrp, what = "MLscale", tail = 0.9, hline = 2 * 1E3)
```

Figure \ref{fig:bitcoin-tail-scale} shows plots identifying the candidates
$\beta = 0.9$ and $\sigma_0 = 2000$ for 
the tail and scale parameters of the exceedance time distribution. 
That is, exceedances of a threshold $\ell$ at the $k$-th largest observed 
magnitude are distributed as 
$$T(\ell) = \text{ML}(0.9, 2000 * k^{-1/0.9}).$$ 
A Hill plot (not shown) of the exceedance times at the level of the 100th 
largest event lends credence to a heavy-tailed distribution with tail
parameter near the value $1$. 


## Solar Flare Data

```{r solar-flare-data, fig.cap="\\label{fig:solar-flare-data}The solar flare time series data."}
flares_mrp <- new_mrp(flares$times, flares$magnitudes)
plot(flares_mrp, p = 0.01)
```



The "complete Hard X Ray Burst Spectrometer event list" 
\footnote{\url{https://umbra.nascom.nasa.gov/smm/hxrbs.html}} 
\cite{HXRBS} is a 
comprehensive reference for all Hard X ray bursts detected with the Hard X 
Ray Burst Spectrometer on NASA's Solar Maximum Mission from the time of 
launch on Feb 14, 1980 to the end of the mission in Dec 1989. Some 12,776 
events were detected in the energy range 30 to 600 keV with the vast 
majority being solar flares. The list includes the start time, peak time, 
duration, and peak rate of each event. We have used "start time" as the 
variable for event times, and "peak rate" as the variable for event 
magnitudes (Figure \ref{fig:solar-flare-data}). 

```{r solar-flare-tail-scale, message=FALSE, fig.cap="\\label{fig:flares}Stability plots for the tail and scale parameter of the Mittag-Leffler distribution of the Solar Flare dataset."}
flares_mrp <- new_mrp(flares$times, flares$magnitudes)
flares_mrp <- flares_mrp("thin", k = 300)
par(mfrow=c(1,2))
plot(flares_mrp, what = "MLtail", hline = 0.85)
plot(flares_mrp, what = "MLscale", tail = 0.85, hline = 350)
```

Figure \ref{fig:flares} shows estimates for the tail and scale parameters 
of the fitted Mittag-Leffler distribution. The dotted line for the tail 
parameter is at $\beta = 0.85$, yielding the plot of (transformed) scale 
estimates $\hat \sigma_0 = k^{1/0.85} \hat \sigma(\ell)$. 
We suggest the estimate $\sigma_0 = 350$. 
The exceedance times of a threshold $\ell$ are hence 
Mittag-Leffler distributed as
$$ T(\ell) \sim {\rm ML}(0.85, 350  k^{-1/0.85})$$
where time is measured in days. 


# Discussion

Comparing the simulated data in Figure \ref{fig:sim} with plots of the 
empirical data \ref{fig:bitcoin-data} and \ref{fig:solar-flare-data}, 
it can be seen that the empirical data show long time intervals without 
*any* event occurring, whereas for real-world data events appear to happen 
continuously. 
This discrepancy vanishes, however, when all but the $k_\text{max}$ 
largest observations are discarded. 
The CTRM model thus models the extreme events, while ignoring the "noise"
events of small magnitudes. 

The CTRM model, moreover, assumes a "pure" power-law for the event 
inter-arrival times. 
Real datasets, however, are often exponentially 
tapered or truncated, see e.g. the discussion of tempered power-law 
distributions by @MeerschaertRoyQin and the truncated Pareto distribution 
by @Aban06. 
This means that for a range of time scales, the fit to a power-law
distribution seems adequate, the power-law character of the distribution 
seems to disappear. 
This behaviour seems to appear in both the Bitcoin data and the Solar-Flare
data: the Hill plot for the tail parameter is increasing towards lighter
tails as the threshold reaches very high values. 
This may mean that the CTRM model may overestimate the heaviness of the
tail of the waiting time distribution. 

# Conclusion

We have proposed the CTRM model for the extremes of "bursty" events. 
Burstiness is a phenomenon of intermittency which has received a lot of 
attention in the recent statistical physics literature. 
The CTRM model is a straightforward generalization of the POT (Peaks over 
Threshold) model, for which the inter-arrival times between threshold 
crossings are exponentially distributed. 
If the Mittag-Leffler tail parameter of the CTRM equals $1$, then the 
CTRM model reproduces this behaviour exactly, showing that the CTRM model 
nests the POT model. 

The scale parameter $\sigma$ of the inter-event distribution follows a 
power-law $\sigma \propto p^{-1/\beta}$, where $\beta \in (0,1)$ is the 
tail parameter of the inter-event distribution and $p$ the probability 
that an event crosses a given threshold. 
From this power law, we have constructed "stability plots", from which 
estimates of $\beta$ and $\sigma$ can be read off. 

We have demonstrated the applicability of the CTRM model with two 
real-world datasets. 
Although the CTRM model possibly overestimates the heaviness of the tail 
of the inter-arrival distribution, it clearly captures that 
the inter-arrival times of threshold crossings scale non-linearly with 
the treshold crossing probability, and follow a clearly non-Poissonian 
behaviour. 
Thus we have shown that the CTRM model is a useful tool for the modelling 
of extremes of bursty events, which requires very little computation and 
which allows for straightforward ways of checking and criticizing model 
assumptions. 




\appendix

# Model-checking plots

## Bitcoin data

```{r bitcoin-cross-cor}
bitcoin_mrp("iidTest")
```

```{r bitcoin-hillPlot}
bitcoin_mrp(what = "hillPlot", hline = 0.85)
```

```{r bitcoin-uncoupled}
bitcoin_mrp("is.uncoupled")
```

## Solar Flare Data

```{r solar-flare-cross-cor}
flares_mrp("iidTest")
```

```{r flares-hillPlot}
flares_mrp(what = "hillPlot", hline = 0.85)
```

```{r flares-uncoupled}
flares_mrp("is.uncoupled")
```




# TODO: 

* Add some GP plots, to show that interest is actually also in the extreme 
  value distribution, not just the inter-event times

* Mention that CTRM and OCTRM have the same distribution in the 
  uncoupled case
  

* Show that the scaling limit for $T(\ell)$ is the same for CTRM and OCTRM


* give a method that jointly estimates beta and sigma



* Mention fractional Poisson Process, cite JStatPlanInf paper by Cahoy




